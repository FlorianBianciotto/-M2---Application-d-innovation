{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import unicodedata\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = minidom.parse('data/train.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaires = mydoc.getElementsByTagName(\"commentaire\")\n",
    "notes = mydoc.getElementsByTagName(\"note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line error 40959\n",
      "line error 138550\n",
      "line error 267600\n",
      "line error 280534\n",
      "line error 307511\n",
      "line error 342799\n",
      "line error 380125\n",
      "line error 528530\n",
      "line error 541831\n",
      "line error 543469\n",
      "line error 621082\n",
      "line error 663582\n"
     ]
    }
   ],
   "source": [
    "row_list = []\n",
    "\n",
    "for i in range(len(notes)):\n",
    "#     if i%20000==0: print(i)\n",
    "    try:\n",
    "        row = {}\n",
    "        row['note'] = notes[i].firstChild.nodeValue\n",
    "        row['commentaire'] = commentaires[i].firstChild.nodeValue\n",
    "        row_list.append(row)\n",
    "    except Exception:\n",
    "        print(\"line error\",i)\n",
    "    \n",
    "train = pd.DataFrame(row_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~«»“”‘\\t\\n\\r'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_list = re.sub(\"[?!'.,]\",'',string.punctuation)\n",
    "punct_list += '«»“”‘'+chr(9)+chr(10)+chr(13)\n",
    "punct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):    \n",
    "    text_nopunct = \"\".join([char for char in text if char not in punct_list])# It will discard all punctuations\n",
    "    return text_nopunct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to Tokenize words\n",
    "def tokenize(text):    \n",
    "    #Tokenize les series de marque de ponctuation, reduit les espaces, supprime les tokens vides\n",
    "    text = unicodedata.normalize('NFKD',text)\n",
    "    whitespace_index = []\n",
    "    for ite in re.finditer(\"!+|\\?+\", text, flags=0):\n",
    "        whitespace_index.append(ite.start(0))\n",
    "        whitespace_index.append(ite.end(0))\n",
    "\n",
    "    for i in reversed(whitespace_index):\n",
    "        text = text[:i]+\" \"+text[i:]\n",
    "    text_clean = re.sub(\"^ | $\",\"\",re.sub(\" +\",\" \",re.sub(\"[,.']+\",\" \",text)))\n",
    "    if len(text_clean) == 0:\n",
    "        return []\n",
    "    tokens = re.split(\"[\\s]\",text_clean)\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english') + nltk.corpus.stopwords.words('french')\n",
    "# stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove Stopwords\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopword]# To remove all stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = nltk.stem.SnowballStemmer('french')\n",
    "\n",
    "def stemming(tokenized_text):\n",
    "    text = [sno.stem(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return stemming(remove_stopwords(tokenize(remove_punct(text).lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['commentaire_punct_clean'] = train['commentaire'].apply(lambda x: remove_punct(x))\n",
    "train['commentaire_tokenized'] = train['commentaire_punct_clean'].apply(lambda x: tokenize(x.lower())) \n",
    "train['commentaire_nostop'] = train['commentaire_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "train['commentaire_stemmed'] = train['commentaire_nostop'].apply(lambda x: stemming(x))\n",
    "train['commentaire_lemmatized'] = train['commentaire_nostop'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>commentaire_punct_clean</th>\n",
       "      <th>commentaire_tokenized</th>\n",
       "      <th>commentaire_nostop</th>\n",
       "      <th>commentaire_stemmed</th>\n",
       "      <th>commentaire_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4,0</td>\n",
       "      <td>\"Ce n'est pas ce qui se trouve en face de vous...</td>\n",
       "      <td>Ce n'est pas ce qui se trouve en face de vous,...</td>\n",
       "      <td>[ce, n, est, pas, ce, qui, se, trouve, en, fac...</td>\n",
       "      <td>[trouve, face, tient, à, côté, cette, phras...</td>\n",
       "      <td>[trouv, fac, tient, à, côté, cet, phras, ta...</td>\n",
       "      <td>[trouve, face, tient, à, côté, cette, phras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3,5</td>\n",
       "      <td>(...) En soi, je n'ai rien contre ce genre de ...</td>\n",
       "      <td>... En soi, je n'ai rien contre ce genre de ré...</td>\n",
       "      <td>[en, soi, je, n, ai, rien, contre, ce, genre, ...</td>\n",
       "      <td>[soi, rien, contre, genre, récit, hyper, codi...</td>\n",
       "      <td>[soi, rien, contr, genr, réc, hyp, codifié, ...</td>\n",
       "      <td>[soi, rien, contre, genre, récit, hyper, codi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4,5</td>\n",
       "      <td>Pour sa troisième réalisation après \"Tron, l'h...</td>\n",
       "      <td>Pour sa troisième réalisation après Tron, l'hé...</td>\n",
       "      <td>[pour, sa, troisième, réalisation, après, t...</td>\n",
       "      <td>[troisième, réalisation, après, tron, héri...</td>\n",
       "      <td>[troisièm, réalis, aprè, tron, héritag, ob...</td>\n",
       "      <td>[troisième, réalisation, après, tron, héri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3,0</td>\n",
       "      <td>Joseph Kosinski offre de nouvelles images ébou...</td>\n",
       "      <td>Joseph Kosinski offre de nouvelles images ébou...</td>\n",
       "      <td>[joseph, kosinski, offre, de, nouvelles, image...</td>\n",
       "      <td>[joseph, kosinski, offre, nouvelles, images, e...</td>\n",
       "      <td>[joseph, kosinsk, offre, nouvel, imag, ébouri...</td>\n",
       "      <td>[joseph, kosinski, offre, nouvelles, image, é...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3,5</td>\n",
       "      <td>J'ai vu un film... qui traite d'un drame humai...</td>\n",
       "      <td>J'ai vu un film... qui traite d'un drame humai...</td>\n",
       "      <td>[j, ai, vu, un, film, qui, traite, d, un, dram...</td>\n",
       "      <td>[vu, film, traite, drame, humain, plus, haute,...</td>\n",
       "      <td>[vu, film, trait, dram, humain, plus, haut, in...</td>\n",
       "      <td>[vu, film, traite, drame, humain, plus, haute,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  note                                        commentaire  \\\n",
       "0  4,0  \"Ce n'est pas ce qui se trouve en face de vous...   \n",
       "1  3,5  (...) En soi, je n'ai rien contre ce genre de ...   \n",
       "2  4,5  Pour sa troisième réalisation après \"Tron, l'h...   \n",
       "3  3,0  Joseph Kosinski offre de nouvelles images ébou...   \n",
       "4  3,5  J'ai vu un film... qui traite d'un drame humai...   \n",
       "\n",
       "                             commentaire_punct_clean  \\\n",
       "0  Ce n'est pas ce qui se trouve en face de vous,...   \n",
       "1  ... En soi, je n'ai rien contre ce genre de ré...   \n",
       "2  Pour sa troisième réalisation après Tron, l'hé...   \n",
       "3  Joseph Kosinski offre de nouvelles images ébou...   \n",
       "4  J'ai vu un film... qui traite d'un drame humai...   \n",
       "\n",
       "                               commentaire_tokenized  \\\n",
       "0  [ce, n, est, pas, ce, qui, se, trouve, en, fac...   \n",
       "1  [en, soi, je, n, ai, rien, contre, ce, genre, ...   \n",
       "2  [pour, sa, troisième, réalisation, après, t...   \n",
       "3  [joseph, kosinski, offre, de, nouvelles, image...   \n",
       "4  [j, ai, vu, un, film, qui, traite, d, un, dram...   \n",
       "\n",
       "                                  commentaire_nostop  \\\n",
       "0  [trouve, face, tient, à, côté, cette, phras...   \n",
       "1  [soi, rien, contre, genre, récit, hyper, codi...   \n",
       "2  [troisième, réalisation, après, tron, héri...   \n",
       "3  [joseph, kosinski, offre, nouvelles, images, e...   \n",
       "4  [vu, film, traite, drame, humain, plus, haute,...   \n",
       "\n",
       "                                 commentaire_stemmed  \\\n",
       "0  [trouv, fac, tient, à, côté, cet, phras, ta...   \n",
       "1  [soi, rien, contr, genr, réc, hyp, codifié, ...   \n",
       "2  [troisièm, réalis, aprè, tron, héritag, ob...   \n",
       "3  [joseph, kosinsk, offre, nouvel, imag, ébouri...   \n",
       "4  [vu, film, trait, dram, humain, plus, haut, in...   \n",
       "\n",
       "                              commentaire_lemmatized  \n",
       "0  [trouve, face, tient, à, côté, cette, phras...  \n",
       "1  [soi, rien, contre, genre, récit, hyper, codi...  \n",
       "2  [troisième, réalisation, après, tron, héri...  \n",
       "3  [joseph, kosinski, offre, nouvelles, image, é...  \n",
       "4  [vu, film, traite, drame, humain, plus, haute,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV(SemiColon-separated-value)\n",
    "train[['note','commentaire_stemmed']].to_csv(\"train_clean_stem.csv\", sep=';')\n",
    "train[['note','commentaire_lemmatized']].to_csv(\"train_clean_lem.csv\", sep=';')\n",
    "#train[['note','commentaire']].to_csv(\"train_clean.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(\"train_clean.csv\", sep=';',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??ce n'e,,,st pa..,.s ce!! qu...     i se.tro???uve en face de!!!!??\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['??',\n",
       " 'ce',\n",
       " 'n',\n",
       " 'e',\n",
       " 'st',\n",
       " 'pa',\n",
       " 's',\n",
       " 'ce',\n",
       " '!!',\n",
       " 'qu',\n",
       " 'i',\n",
       " 'se',\n",
       " 'tro',\n",
       " '???',\n",
       " 'uve',\n",
       " 'en',\n",
       " 'face',\n",
       " 'de',\n",
       " '!!!!',\n",
       " '??']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest = \"??Ce n'e,,,st pa..,.s ce!! qu...     i se.tro???uve en face de!!!!??\"\n",
    "ttest = remove_punct(ttest.lower())\n",
    "print(ttest)\n",
    "ttest = tokenize(ttest)\n",
    "\n",
    "ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ngram_vect = CountVectorizer(ngram_range=(2,2),analyzer=clean_text) # It applies only bigram vectorizer\n",
    "# X_counts = ngram_vect.fit_transform(train['commentaire'])\n",
    "# X_counts_df = pd.DataFrame(X_counts.toarray(), columns=ngram_vect.get_feature_names())\n",
    "\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(train['commentaire'])\n",
    "#X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7\n",
       "1         6\n",
       "2         8\n",
       "3         5\n",
       "4         6\n",
       "         ..\n",
       "665945    7\n",
       "665946    5\n",
       "665947    6\n",
       "665948    5\n",
       "665949    6\n",
       "Name: note, Length: 665950, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelfloat = train['note'].apply(lambda x: re.sub(\",\",'.',x))\n",
    "# labelfloat = train['note'].apply(lambda x: re.sub(\",\",'.',x))\n",
    "notes = {0.5: 0,1.0: 1,1.5: 2,2.0: 3,2.5: 4,3.0: 5,3.5: 6,4.0: 7,4.5: 8,5.0: 9}\n",
    "noteINT = labelfloat.apply(lambda x: notes[float(x)])\n",
    "noteINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(100)\n",
    "X_tfidf_reduced = svd.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tfidf_reduced.to_csv(\"X_tfidf_reduced.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_tfidf_reduced,noteINT, test_size=0.2, random_state=1)\n",
    "clf = LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "#clf.score(x_test,y_test)\n",
    "\n",
    "#print(clf.predict(X_tfidf_reduced[10].reshape(1,-1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28197623, -0.01102014, -0.07466781, ...,  0.00298113,\n",
       "         0.02295452,  0.01222901],\n",
       "       [ 0.20072312, -0.06687433,  0.02126142, ...,  0.00876331,\n",
       "        -0.02653064,  0.02024149],\n",
       "       [ 0.24677846,  0.01265841,  0.09127958, ..., -0.00046889,\n",
       "         0.0307302 , -0.01408136],\n",
       "       ...,\n",
       "       [ 0.02001199,  0.01413156, -0.02031568, ..., -0.00076455,\n",
       "        -0.00250706,  0.00261329],\n",
       "       [ 0.09925962, -0.05297585,  0.01445042, ...,  0.0430905 ,\n",
       "         0.02407453, -0.02110756],\n",
       "       [ 0.0948539 ,  0.00459399, -0.01241713, ...,  0.06926825,\n",
       "         0.03563151, -0.01739512]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testxml = minidom.parse('data/test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaires = testxml.getElementsByTagName(\"commentaire\")\n",
    "review_ids = testxml.getElementsByTagName(\"review_id\")\n",
    "#notes = testxml.getElementsByTagName(\"note\")\n",
    "row_list = []\n",
    "for i in range(len(commentaires)):\n",
    "#     if i%20000==0: print(i)\n",
    "    try:\n",
    "        row = {}\n",
    "        #row['note'] = notes[i].firstChild.nodeValue\n",
    "        row['review_id'] = review_ids[i].firstChild.nodeValue\n",
    "        row['commentaire'] = commentaires[i].firstChild.nodeValue\n",
    "        row_list.append(row)\n",
    "    except Exception:\n",
    "        print(\"line error\",i)\n",
    "    \n",
    "test = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>commentaire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review_59354742</td>\n",
       "      <td>12 jours, un film que j'ai raté à sa sortie et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review_62570109</td>\n",
       "      <td>Ces lueurs dans ces yeux... Soit ils sont tous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review_58180650</td>\n",
       "      <td>Il s’agit d’un documentaire sans la moindre ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review_57696986</td>\n",
       "      <td>un documentaire magnifique dans cette unité ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review_57736972</td>\n",
       "      <td>Un documentaire très intéressant, quand bien m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         review_id                                        commentaire\n",
       "0  review_59354742  12 jours, un film que j'ai raté à sa sortie et...\n",
       "1  review_62570109  Ces lueurs dans ces yeux... Soit ils sont tous...\n",
       "2  review_58180650  Il s’agit d’un documentaire sans la moindre ac...\n",
       "3  review_57696986  un documentaire magnifique dans cette unité ly...\n",
       "4  review_57736972  Un documentaire très intéressant, quand bien m..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()\n",
    "tfidf_test_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_test_tfidf = tfidf_test_vect.fit_transform(test['commentaire'])\n",
    "#svd = TruncatedSVD(100)\n",
    "X_test_tfidf_reduced = svd.fit_transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review , prediction\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = clf.predict(X_test_tfidf_reduced)\n",
    "f = open(\"results.txt\", \"a\")\n",
    "print(\"review , prediction\")\n",
    "notes_virgules = {\"0,5\": 0,\"1,0\": 1,\"1,5\": 2,\"2,0\": 3,\"2,5\": 4,\"3,0\": 5,\"3,5\": 6,\"4,0\": 7,\"4,5\": 8,\"5,0\": 9}\n",
    "\n",
    "key_list = list(notes_virgules.keys())\n",
    "val_list = list(notes_virgules.values())\n",
    "for i in range(len(y_pred_test)):\n",
    "    position = val_list.index(y_pred_test[i])\n",
    "    n = key_list[position]\n",
    "    f.write(test.iloc[i]['review_id']+\" \"+str(n)+\"\\n\")\n",
    "    #print(test.iloc[i]['review_id'],\" \",str(n),\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['0,5', '1,0', '1,5', '2,0', '2,5', '3,0', '3,5', '4,0', '4,5', '5,0']\n"
     ]
    }
   ],
   "source": [
    "#test.iloc[[0]]['review_id'][0]\n",
    "print(y_pred_test[0])\n",
    "\n",
    "\n",
    "print(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "my_dict ={\"java\":100, \"python\":112, \"c\":11}\n",
    " \n",
    "# list out keys and values separately\n",
    "key_list = list(notes.keys())\n",
    "val_list = list(notes.values())\n",
    " \n",
    "# print key with val 100\n",
    "position = val_list.index(y_pred_test[0])\n",
    "print(key_list[position])\n",
    " \n",
    "# print key with val 112\n",
    "position = val_list.index(2)\n",
    "print(key_list[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line error 46611\n",
      "line error 66228\n"
     ]
    }
   ],
   "source": [
    "mydoc = minidom.parse('data/dev.xml')\n",
    "commentaires = mydoc.getElementsByTagName(\"commentaire\")\n",
    "notes = mydoc.getElementsByTagName(\"note\")\n",
    "row_list = []\n",
    "\n",
    "for i in range(len(notes)):\n",
    "#     if i%20000==0: print(i)\n",
    "    try:\n",
    "        row = {}\n",
    "        row['note'] = notes[i].firstChild.nodeValue\n",
    "        row['commentaire'] = commentaires[i].firstChild.nodeValue\n",
    "        row_list.append(row)\n",
    "    except Exception:\n",
    "        print(\"line error\",i)\n",
    "    \n",
    "dev = pd.DataFrame(row_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['commentaire_stemmed'] = dev['commentaire'].apply(lambda x: clean_text(x))\n",
    "dev[['note','commentaire_stemmed']].to_csv(\"dev_clean_stem.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = minidom.parse('data/test.xml')\n",
    "commentaires = mydoc.getElementsByTagName(\"commentaire\")\n",
    "review_ids = mydoc.getElementsByTagName(\"review_id\")\n",
    "row_list = []\n",
    "for i in range(len(commentaires)):\n",
    "#     if i%20000==0: print(i)\n",
    "    try:\n",
    "        row = {}\n",
    "        #row['note'] = notes[i].firstChild.nodeValue\n",
    "        row['review_id'] = review_ids[i].firstChild.nodeValue\n",
    "        row['commentaire'] = commentaires[i].firstChild.nodeValue\n",
    "        row_list.append(row)\n",
    "    except Exception:\n",
    "        print(\"line error\",i)\n",
    "    \n",
    "test = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['commentaire_stemmed'] = test['commentaire'].apply(lambda x: clean_text(x))\n",
    "test[['review_id','commentaire_stemmed']].to_csv(\"test_clean_stem.csv\", sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
